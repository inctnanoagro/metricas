# INCT NanoAgro - MÃ©tricas - Claude Context

## Project Overview

This repository consolidates scientific production data from researchers affiliated with INCT NanoAgro. The project extracts, parses, and validates data from Lattes CVs to create a structured institutional database for accountability, impact reporting, and strategic analysis.

## Key Objectives

- Extract and parse scientific production records from Lattes HTML CVs
- Validate and organize data using a JSON schema
- Support institutional reporting and impact analysis
- Provide a structured layer on top of official sources (Lattes)

## Project Structure

```
metricas/
â”œâ”€â”€ scripts/                    # Main workflow scripts
â”‚   â”œâ”€â”€ ingestao_lattes.py     # Lattes HTML ingestion
â”‚   â”œâ”€â”€ agregacao.py           # Data aggregation
â”‚   â”œâ”€â”€ validacao.py           # Schema validation
â”‚   â””â”€â”€ prefill_from_lattes.py # Prefill from Lattes data
â”œâ”€â”€ metricas_lattes/           # Core parsing library
â”‚   â””â”€â”€ parsers/               # HTML parsers for different record types
â”‚       â”œâ”€â”€ base.py            # Base parser functionality
â”‚       â”œâ”€â”€ artigos.py         # Article parser
â”‚       â””â”€â”€ capitulos.py       # Book chapter parser
â”œâ”€â”€ schema/                    # JSON Schema definitions
â”‚   â””â”€â”€ producoes.schema.json  # Production records schema v1.0.0
â”œâ”€â”€ tests/                     # Unit tests
â”‚   â”œâ”€â”€ test_parsers_artigos.py
â”‚   â”œâ”€â”€ test_parsers_capitulos.py
â”‚   â””â”€â”€ test_cli_prefill.py
â”œâ”€â”€ data/                      # Input/source data (gitignored)
â”œâ”€â”€ outputs/                   # Generated outputs (gitignored)
â””â”€â”€ docs/                      # Documentation and manuals
```

## Data Schema (v1.0.0)

The project uses a strict JSON Schema for all production records. Key components:

### Record Types
- LIVRO
- CAPITULO_DE_LIVRO
- TRABALHO_COMPLETO_EM_ANAIS
- RESUMO_EXPANDIDO_EM_ANAIS
- ARTIGO_ACEITO_PARA_PUBLICACAO

### Schema Structure
Each record contains:
- **schema_version**: Version identifier (1.0.0)
- **record_id**: Stable identifier (SHA1-based)
- **record_type**: Production type enum
- **provenance**: Source tracking and audit trail
  - source_system: LATTES_HTML
  - source_doc_id: Source file identifier
  - extraction_timestamp_utc: ISO 8601 timestamp
  - section_key: Canonical section identifier
  - item_number: Ordinal number from Lattes
- **content**: Extracted data
  - raw_text: Exact text from HTML
  - raw_html: HTML snippet (optional)
  - doi_url: DOI link if available
  - people: Authors/organizers with Lattes URIs
  - bibliography: Parsed bibliographic fields
- **fingerprints**: Deduplication and integrity
  - text_sha1: SHA1 of raw text
  - text_sha256: SHA256 of raw text
  - dedupe_key: Deterministic deduplication key
- **quality**: Parse confidence and warnings

## Technical Details

### Dependencies
- Python 3.x
- beautifulsoup4==4.12.2
- pytest==7.4.3
- pytest-cov==4.1.0

### Data Flow
1. HTML files from Lattes CVs placed in `data/`
2. Parsers extract structured records from HTML
3. Records validated against JSON schema
4. Aggregation and deduplication
5. Output to `outputs/` directory

### Parser Implementation
- Base parser in `metricas_lattes/parsers/base.py` provides core functionality
- Type-specific parsers extend base class
- Each parser handles specific Lattes HTML sections
- Preserves raw text as source of truth
- Generates cryptographic fingerprints for integrity

### Testing Strategy
- Unit tests for each parser type
- CLI integration tests
- Coverage tracking with pytest-cov

## Development Status

ðŸš§ In active development

## Git Status
- Main branch: `main`
- Modified: `schema/producoes.schema.json`
- Untracked directories: `data/`, `outputs/`, `metricas_lattes/`, `tests/`

## Important Notes for AI Assistants

1. **Data Integrity**: Always preserve `raw_text` as the source of truth. All parsed fields must be derivable from raw_text.

2. **Schema Compliance**: All records must validate against `schema/producoes.schema.json`. The schema is strict with `additionalProperties: false`.

3. **Provenance Tracking**: Every record must have complete provenance metadata for audit purposes.

4. **Fingerprinting**: Use SHA1/SHA256 hashes for deduplication and integrity verification.

5. **Lattes HTML**: The source data is HTML exported from Lattes platform. Encoding issues (especially UTF-8) may be present.

6. **Testing**: Run tests with pytest before committing changes. Maintain test coverage.

7. **File Locations**:
   - Schema definitions: `schema/`
   - Source data: `data/` (gitignored)
   - Outputs: `outputs/` (gitignored)
   - Never commit data files or outputs

8. **Code Style**: Follow existing patterns in parser implementations. Keep parsers modular and testable.

## Common Tasks

### Running Tests
```bash
pytest tests/
pytest --cov=metricas_lattes tests/
```

### Schema Validation
Validate records against the JSON schema using standard JSON Schema validators.

### Adding New Record Types
1. Update schema enum in `record_type`
2. Add section_key to enum if needed
3. Implement parser in `metricas_lattes/parsers/`
4. Add corresponding tests
5. Update this documentation
